---
title: Imputación de datos
author: cabrokiller
date: '2018-03-05'
slug: imputacion-de-datos
categories:
  - R
tags:
  - Imputación
  - PCA
draft: false
coverImage: "https://res.cloudinary.com/dcfq7gkhs/image/upload/v1520669139/640px-Charles_Babbage_Difference_Engine_No2_Gears_on_Drawing.jpg"
coverCaption: "Babbage difference engine"
coverMeta: in
coverSize: full
showTags: true
showPagination: true
showSocial: true
showDate: true
thumbnailImagePosition: right
---



<div id="imputacion-de-datos-en-r" class="section level1">
<h1>Imputación de datos en R</h1>
<!-- toc -->
<div id="introduccion" class="section level2">
<h2>Introducción</h2>
<p>Estás preparado para aplicar todo el conocimiento para estrujar esa base,
pero te encuentras con un problema… Faltan datos. Casos incompletos, escalas
sin pasar, <em>dropouts</em>, o que el pobre desgraciado del interno asignado para
pasar los datos al ordenador era un poco vago… Pues en ciencias y sobretodo
en las ciencias de la salud, lo más común encontrar bases de datos <strong>incompletas</strong>.
Por otra parte, la mayoría de los análisis estadísticos requieren de <em>casos</em>
completos, es decir, algo hay que hacer con los <strong>valores ausentes</strong> (NA’s).</p>
<p>Una alternativa fácil es <em>eliminar</em> los NA’s. Ya está!, fuera con todos los
casos incompletos y palante… pero esto tiene dos problemas.
1. A menos número de casos disminuye la potencia del estudio,
y esto no es bueno, no?
2. Hay un sesgo potencial de selección, si es que la falta de datos tiene relación con
alguna de las variables relevantes (dependientes o indepes)</p>
<p>Pues ¿qué diablos hacemos entonces? Podemos <em>imputar</em> (que no es un insulto)
los datos que faltan. <em>Imputar</em> viene a ser, el rellenar los NA’s con <em>el mejor valor posible</em>.
Existen varias técnicas y maneras de definir este valor. Pero antes de esto,
debemos caracterizar que patrón siguen nuestras datos faltantes.</p>
</div>
<div id="analisis-exploratorio-de-nas" class="section level2">
<h2>Análisis exploratorio de NA’s</h2>
<p>El primer paso como en cualquier trabajo de análisis de datos decente, implica un <em>análisis exploratorio</em> de los NA. En R esto esto se consigue fácil y de manera gráfica con a librería <code>VIM</code>.</p>
<pre class="r"><code># cargamos las librerías necesarias
pacman::p_load(tidyverse, VIM, lattice, missForest, mice)</code></pre>
<pre class="r"><code>set.seed(41)
# creamos un patrón aleatório de NA
mis_datos &lt;-
   diamonds %&gt;%
   sample_n(200) %&gt;%
   prodNA(noNA = 0.08)

mis_datos %&gt;%
    aggr(col=mdc(1:2), numbers=T, sortVars=T,
         cex.axis=.8, gap=3, only.miss = F, combined = F,
         ylab=c(&quot;Proportion of missingness&quot;,&quot;Missingness Pattern&quot;))</code></pre>
<pre><code>## Warning in plot.aggr(res, ...): not enough vertical space to display
## frequencies (too many combinations)</code></pre>
<p><img src="/rmarkdown-libs/figure-html4/unnamed-chunk-2-1.png" width="672" /></p>
<pre><code>## 
##  Variables sorted by number of missings: 
##  Variable Count
##       cut 0.105
##     table 0.100
##         x 0.095
##         y 0.095
##     depth 0.075
##     price 0.075
##         z 0.075
##     color 0.065
##   clarity 0.060
##     carat 0.055</code></pre>
<p>La función <code>VIM::aggr</code> permite tener una representación gráfica de los NA y permite ver el patrón que estos presentan. En est ecaso podemos apreciar que el patrón de NA’s es mas bien
homogeneo, y que la hay un porcentaje alto de casos completos. También es util ver el porcentaje de NA’s <em>por variable</em>, que en este caso, ronda el 8%.</p>
<div id="cantidad-de-nas" class="section level3">
<h3>Cantidad de NA’s</h3>
<p>Un primer punto de discusión es que tan <em>tolerantes</em> vamos a ser. Que la tolerancia es
buena, lo sabemos, pero ¿Cuantos NA’s podemos tolerar para decir que podemos
imputar los faltantes? No lo tengo tan claro, pero en la mayoría de las aproximaciones
defienden que el máximo porcentaje de NA’s no debe superar entre el 5 al 10%.</p>
<p>Para ver posibles <em>relaciones</em> entre los valores ausentes, se muy util un gráfico de cajas
de las variables.</p>
<pre class="r"><code>mis_datos %&gt;%
    select(carat, price) %&gt;%
    marginplot()</code></pre>
<p><img src="/rmarkdown-libs/figure-html4/unnamed-chunk-3-1.png" width="672" /></p>
<p>En este gráfico de <strong>dos</strong> de las variables (hay que ir de dos en dos) se aprecia
la distribución de la variables en <strong>azul</strong> y en rojo, la distribución <em>removiendo</em> los NA’s
de manera cruzada, es decir, en el eje <strong>y</strong> en azul esta la disrtibución de la variable <em>price</em>
de la muestra completa, y en rojo la distribucion <em>removiendo</em> los casos que <em>no tienen</em> un valor
para <em>carat</em>. Esto permite ver potenciales relacines entre la ausnecia de valor y
la distribución de alguna variable.</p>
</div>
<div id="tipos-de-nas" class="section level3">
<h3>Tipos de NA’s</h3>
<p>Se pueden establecer tres tipos de patrones de <a href="https://en.wikipedia.org/wiki/Missing_data#Missing_at_random">valores ausentes:</a>
1. NA totalmente aleatorio (“missing completely at random, o MCAR”) en el que no hay un patrón establecido. El evento por el que hay un valor ausente es independiente de las variables observadas u otros parámetros de interés. Como sospechais es el patrón menos habitual…</p>
<ol start="2" style="list-style-type: decimal">
<li><p>NA aleatorio (“missing at random, o MAR”), en el cual la ausencia de datos no completamente aleatoria, pero en la que se puede dar cuenta de la información faltante con los datos existentes, es decir, en la que se puede hacer una estimación coherentes de los datos faltantes.</p></li>
<li><p>NA no aleatorio (“missing not at random o MNAR), en el que hay una relación directa entre el motivo de la ausencia de datos y su propio valor.</p></li>
</ol>
<p>Cualquier técnica de imputación requiere de que los NA’s sigan un patrón MCAR o MAR. En casos en los que el patrón de NA’s siga un patrón de MNAR, hace necesario que posteriormente se deba hacer un <a href="https://en.wikipedia.org/wiki/Sensitivity_analysis">análisis de sensibilidad</a> para valorar la influencia de la imputación en el grado de incertidumbre del modelo generado. Si bien no es física cuántica, se lo parece, y si queréis adentraros en el tema hay una <a href="https://gerkovink.github.io/miceVignettes/Sensitivity_analysis/Sensitivity_analysis.html">viñeta</a> del paquete <code>mice</code> que trata de ello.</p>
</div>
</div>
<div id="metodos-de-imputacion-de-datos" class="section level2">
<h2>Métodos de imputación de datos</h2>
<div id="tendencia-central" class="section level3">
<h3>Tendencia central</h3>
<p>Una primera alternativa, la de <em>toda la vida</em>, es imputar con algún estadístico de tendencia central (media, mediana, moda). Es decir, cambiamos todos los NA por el promedio de los datos que <em>si</em> tenemos. ¿Ventajas? Fácil de hacer. ¿Problema? estamos disminuyendo artificialmente la variabilidad de la muestra. La implementación en R es relativamente fácil como se muestra a continuación, utilizando el universo de librerías <code>tidyverse</code>.</p>
<pre class="r"><code># función para calcular la moda estadística
calc_moda &lt;- function(x) {
    z &lt;- table(as.vector(x))
    names(z)[z == max(z)]
}

imp_media &lt;-
    mis_datos %&gt;%
# media para variables numéricas
    mutate_at(
       vars(carat, depth:z),
       funs(ifelse(is.na(.), mean(., na.rm = T), .))) %&gt;%
# moda para variables categóricas
    mutate_at(
       vars(cut:clarity),
       funs(as.ordered(ifelse(is.na(.), calc_moda(.), as.character(.)))))</code></pre>
<div id="revision-visual-de-imputaciones" class="section level4">
<h4>Revisión visual de imputaciones</h4>
<p>Con los datos imputados podemos ver gráficamente cuánto se ajusta nuestro <em>invento</em> con la base original.</p>
<pre class="r"><code>mis_datos$.imp &lt;- &quot;original&quot;
imp_media$.imp &lt;- &quot;imputado&quot;
imp_media %&gt;%
    rbind(mis_datos) %&gt;%
    select(carat, depth, price, z, .imp) %&gt;%
    gather(key, value, -.imp) %&gt;%
    ggplot(aes(x = value, color = .imp))+
    geom_density(size=0.8) +
    facet_wrap(~ key, scales = &quot;free&quot;) +
    scale_color_brewer(type = &quot;qual&quot;, palette = 6, direction = 1) +
    theme_minimal() + labs(title=&quot;Imputación con media aritmética - variables numéricas&quot;)</code></pre>
<p><img src="/rmarkdown-libs/figure-html4/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>imp_media %&gt;%
    rbind(mis_datos) %&gt;%
    select(color, cut, .imp) %&gt;%
    gather(key, value, -.imp) %&gt;%
    na.omit() %&gt;%
    ggplot(aes(x = value, fill = .imp))+
    geom_bar(alpha = 0.8, position = position_dodge()) +
    facet_wrap(~ key, scales = &quot;free&quot;) +
    scale_fill_brewer(type = &quot;qual&quot;, palette = 6, direction = 1) +
    theme_minimal() + labs(title=&quot;Imputación con moda - variables categóricas&quot;)</code></pre>
<p><img src="/rmarkdown-libs/figure-html4/unnamed-chunk-5-2.png" width="672" /></p>
<p>Es fácilmente apreciable como tanto en las variables numéricas como en las categóricas, la tendencia central está exagerada y se aleja de la distribución original.</p>
</div>
</div>
<div id="imputacion-multiple" class="section level3">
<h3>Imputación múltiple</h3>
<p>Una de las metodologías más utilizadas para la obtención de una muestra imputada más <em>correcta</em> es la que utiliza técnicas de imputación múltiple, es decir imputar más de una base de datos. Esto permite utilizar las <em>n</em> bases imputadas para hacer <em>n</em> modelos, que posteriormente se <em>poolean</em> (lo siento, no se como diablos se traduce eso…) con la ventaja de que el modelo final da cuenta de la incerteza del modelo.</p>
<p>La mayoría de las librerías permiten calibrar bastante la generación de la imputación, además de la metodología utilizada. Uno de los paquetes mejor documentados y <em>de moda</em> es el <a href="http://stefvanbuuren.github.io/mice/">mice</a></p>
<p>El proceso es relativamente fácil y está muy bien documentado en las viñetas. El método de imputación por definición es el <em>predictive mean matching</em> para variables numéricas, <em>logistic imputation</em> para categoriales binarias y <em>polytomous regression imputation</em> para categoriales de más de dos factores. Para la utilización se usa la función <code>mice</code> que genera un objetos <code>mids</code> con las <em>n</em> bases imputadas. La librería trae además varios <em>metodos</em> para utilizar directamente los objetos <code>mids</code> en modelos estadísticos como regresiones lineales.<br />
Funciona mejor o no? Pues lo miramos gráficamente…</p>
<pre class="r"><code>pacman::p_load(mice)
imp_mice &lt;- mice(select(mis_datos, -.imp))</code></pre>
<pre><code>## 
##  iter imp variable
##   1   1  carat  cut  color  clarity  depth  table  price  x  y  z
##   1   2  carat  cut  color  clarity  depth  table  price  x  y  z
##   1   3  carat  cut  color  clarity  depth  table  price  x  y  z
##   1   4  carat  cut  color  clarity  depth  table  price  x  y  z
##   1   5  carat  cut  color  clarity  depth  table  price  x  y  z
##   2   1  carat  cut  color  clarity  depth  table  price  x  y  z
##   2   2  carat  cut  color  clarity  depth  table  price  x  y  z
##   2   3  carat  cut  color  clarity  depth  table  price  x  y  z
##   2   4  carat  cut  color  clarity  depth  table  price  x  y  z
##   2   5  carat  cut  color  clarity  depth  table  price  x  y  z
##   3   1  carat  cut  color  clarity  depth  table  price  x  y  z
##   3   2  carat  cut  color  clarity  depth  table  price  x  y  z
##   3   3  carat  cut  color  clarity  depth  table  price  x  y  z
##   3   4  carat  cut  color  clarity  depth  table  price  x  y  z
##   3   5  carat  cut  color  clarity  depth  table  price  x  y  z
##   4   1  carat  cut  color  clarity  depth  table  price  x  y  z
##   4   2  carat  cut  color  clarity  depth  table  price  x  y  z
##   4   3  carat  cut  color  clarity  depth  table  price  x  y  z
##   4   4  carat  cut  color  clarity  depth  table  price  x  y  z
##   4   5  carat  cut  color  clarity  depth  table  price  x  y  z
##   5   1  carat  cut  color  clarity  depth  table  price  x  y  z
##   5   2  carat  cut  color  clarity  depth  table  price  x  y  z
##   5   3  carat  cut  color  clarity  depth  table  price  x  y  z
##   5   4  carat  cut  color  clarity  depth  table  price  x  y  z
##   5   5  carat  cut  color  clarity  depth  table  price  x  y  z</code></pre>
<pre class="r"><code>imp_mice %&gt;%
    complete(action = &quot;long&quot;) %&gt;%
    select(-.id) %&gt;%
    rbind(mis_datos) %&gt;%
    select(carat, depth, price, z, .imp) %&gt;%
    gather(key, value, -.imp) %&gt;%
    ggplot(aes(x = value, color = .imp))+
    geom_density(size = 0.8, alpha = .8) +
    facet_wrap(~ key, scales = &quot;free&quot;) +
    scale_color_brewer(type = &quot;seq&quot;, palette = 8) +
    theme_minimal() + labs(title=&quot;Imputación con media aritmética - variables numéricas&quot;)</code></pre>
<pre><code>## Warning: Removed 56 rows containing non-finite values (stat_density).</code></pre>
<p><img src="/rmarkdown-libs/figure-html4/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>imp_mice %&gt;%
    complete(action = &quot;long&quot;) %&gt;%
    select(-.id) %&gt;%
    select(color, cut, .imp) %&gt;%
    gather(key, value, -.imp) %&gt;%
    ggplot(aes(x = value, fill = .imp))+
    geom_bar(alpha = 0.8, position = position_dodge()) +
    facet_wrap(~ key, scales = &quot;free&quot;) +
    scale_fill_brewer(type = &quot;seq&quot;, palette =8) +
    theme_minimal() + labs(title=&quot;Imputación con moda - variables categóricas&quot;)</code></pre>
<pre><code>## Warning: attributes are not identical across measure variables;
## they will be dropped</code></pre>
<p><img src="/rmarkdown-libs/figure-html4/unnamed-chunk-6-2.png" width="672" /></p>
<p>Se ajusta mejor ¿no? y eso que no fue necesario tocar los parámetros por definición y con sólo 5 iteraciones. El paquete <code>mice</code> tiene un montón de funciones para ajustar el modelo de predicción. Además de los modelos por definición, <code>mice</code> acepta varios tipos de modelamiento, incluyendo <em>modelos bayesianos</em>, <em>análisis lineal discriminante</em>, y modelos de aprendizaje de máquinas más complejos como el <em>Random Forest</em>.</p>
<p>Si les interesa esta aproximacion metanse a leer las <a href="https://cran.r-project.org/web/packages/mice/vignettes/resources.html">viñetas</a>, que están super bien explicadas. Si están pirados, hay un <a href="http://www.stefvanbuuren.nl/mi/FIMD.html">libro</a> del autor (Van Buuren, S.).</p>
</div>
<div id="imputacion-simple-o-multiple-para-pca" class="section level3">
<h3>Imputación simple o múltiple para PCA</h3>
<p>Un problema de las imputaciones múltiples es que dependiendo del trato que daremos a los datos, puede no haber un método estandarizado para lidiar con ellos. Es el caso del análisis de componentes principales (PCA) donde no está muy bien establecida una metodología para lidiar con los NA y donde no hay un método específico de la librería <code>mice</code>. Una aproximación útil es la de utilizar es la librería <a href="http://factominer.free.fr/missMDA/index.html"><code>missMDA</code></a>, un <em>compañero</em> de la excelente librería para PCA <a href="http://factominer.free.fr/index.html"><code>FactoMineR</code></a> de <a href="http://math.agrocampus-ouest.fr/infoglueDeliverLive/membres/Francois.Husson">François Husson</a>, <a href="http://juliejosse.com/">Julie Josse</a> y <a href="http://sebastien.ledien.free.fr">Sébastien Lê</a></p>
<p><code>missMDA</code> permite la imputación de datos de tal manera de que los valores imputados no tengan mayor repercusión en el resultado del PCA utilizando métodos de reducción de la dimensionalidad (para más detalles de cómo lo hace, espabilar y mirar la <a href="http://factominer.free.fr/missMDA/index.html">documentación</a>).</p>
<p>En resumen el método se aplica así::
1. calcular el número de dimensiones a utilizar para la imputación con la función <code>estim_ncpPCA</code>.
2. Completar la base utilizando el número de dimensiones calculada con <code>imputePCA</code>.
3. Visualizar de manera gráfica la <strong>incertidumbre</strong> de la imputación con la función <code>MIPCA</code>.</p>
<p>En el siguiente ejemplo utilizamos una base más apropiada para PCA. Utilizamos la base <code>geno</code> del paquete <code>missMDA</code> que contiene información de genotipos y ambiente de cultivo, con NA’s</p>
<pre class="r"><code>library(missMDA)
data(geno)

nb&lt;-
    geno %&gt;%
    estim_ncpPCA(ncp.max=10)</code></pre>
<pre><code>## Warning in impute(X, ncp = ncp, scale = scale, method = method, threshold =
## threshold, : Stopped after 1000 iterations</code></pre>
<pre class="r"><code>imp_MDA &lt;-
    geno %&gt;%
    imputePCA(ncp = nb$ncp) %&gt;%
    purrr::pluck(1) %&gt;%
    as.tibble()

check_MDA &lt;-
    geno %&gt;%
    MIPCA(ncp=nb$ncp, nboot = 100)

plot(check_MDA)</code></pre>
</div>
</div>
</div>
