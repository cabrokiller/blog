---
title: Imputación de datos
author: cabrokiller
date: '2018-01-03'
categories:
  - R
tags:
  - r
  - imputacion
slug: imputacion
draft: true
---



<div id="imputacion-de-datos-en-r" class="section level1">
<h1>Imputación de datos en R</h1>
<div id="intro" class="section level2">
<h2>Intro</h2>
<p>Está sentado frente al ordenador, preparado para aplicar todo el conocmiento que posee para explotar una base de datos. Pero se encuentra con un problema… Faltan datos. Casos incompletos, escalas sin pasar, <em>dropouts</em>, o que el desgraciado interno asignado a pasar los datos era un poco vago… En ciencias y sobretodo en las ciencias de la salud es común encontrar bases de datos incompletas. Para él análisis de datos usualmente es necesario elegir alguna metodología para lidiar con estos <em>valores ausentes</em> (NA’s).</p>
<p>Una alternativa es <em>eliminar</em> los NA’s. Ya está!, fuera con todos los casos incompletos, pero esto tiene dos proeblmas.
1. A menos número de casos disminuye la potencia del estudio, y esto no es bueno, no?
2. Hay un sesgo de selección si es que la falta de datos tiene relación con alguna de las variables relevantes.</p>
<p>Pues ¿y que diablos hacemos entonces? pues podemos <em>imputar</em> los datos que faltan.</p>
</div>
<div id="explorar-na" class="section level2">
<h2>Explorar NA</h2>
<p>El primer paso como en cualquier trabajo de análisis de datos decente, implica un <em>análisis exploratorio</em> de los NA. En R esto esto se cosigue fácil y de manera gráfica con a librería <code>VIM</code>.</p>
<pre class="r"><code># cargamos las librerías necesarias
pacman::p_load(tidyverse, VIM, lattice, missForest, mice)

set.seed(41)
# creamos un patrón aleatório de NA 
mis_datos &lt;-
   diamonds %&gt;%
   sample_n(500) %&gt;%
   prodNA(noNA = 0.08)

mis_datos %&gt;%
    aggr(col=mdc(1:2), numbers=F, sortVars=T,
         cex.axis=.8, gap=3, only.miss = F, combined = F,
         ylab=c(&quot;Proportion of missingness&quot;,&quot;Missingness Pattern&quot;))</code></pre>
<p><img src="/rmarkdown-libs/figure-html4/unnamed-chunk-1-1.png" width="672" /></p>
<pre><code>## 
##  Variables sorted by number of missings: 
##  Variable Count
##     price 0.094
##   clarity 0.092
##     carat 0.088
##     table 0.086
##       cut 0.082
##     color 0.076
##     depth 0.074
##         x 0.074
##         y 0.072
##         z 0.062</code></pre>
<p>La funcion <code>VIM::aggr</code> permite tener una representación gráfica de los NA y permite ver el patrón que estos presentan. En general se pueden establecer tres tipos de patrones de <a href="https://en.wikipedia.org/wiki/Missing_data#Missing_at_random">valores ausentes:</a>
1. NA totalmente aleatorio (“missing completely at random, o MCAR”) en el que no hay un patrón establecido. El evento por el que hay un valor ausente es independiente de las variables observadas u otros parámetros de interés. Como sospechais es el patrón menos habitual…</p>
<ol start="2" style="list-style-type: decimal">
<li><p>NA aleatorio (“missing at random, o MAR”), en el cual la ausencia de datos no completamente aleatoria, pero en la que se puede dar cuenta de la iformación faltante con los datos existentes, es decir, en la que se puede hacer una estimacion coheerntes de los datos faltantes.</p></li>
<li><p>NA no aleatorio (“missing not at random o MNAR), en el que hay una relacion directa entre el motivo de la ausencia de datos y su propio valor.</p></li>
</ol>
</div>
<div id="metodos-de-imputacion-de-datos" class="section level2">
<h2>Métodos de imputación de datos</h2>
<div id="tenedencia-central" class="section level3">
<h3>tenedencia central</h3>
<p>Una primera alternbativa, la de <em>toda la vida</em>, es imputar con algún estadístico de tendencia central (media, mediana, moda). Es decir, cambiamos todos los NA por el promedio de los datos que <em>si</em> tenemos. ¿Ventajas? Facil de hacer. ¿Problema? stamos disminyendo artificialmente la variabilidad de la muestra. La implementación en R es realativamente fácil como se muestra a continuación.</p>
<pre class="r"><code>calc_moda &lt;- function(x) {
   z &lt;- table(as.vector(x))
   names(z)[z == max(z)]
}

datos_imp &lt;- 
   mis_datos %&gt;%
# Media para variables numéricas
   mutate_at(
      vars(carat, depth:z),
      funs(ifelse(is.na(.), mean(., na.rm = T), .))) %&gt;%
# Moda para variables categóricas
   mutate_at(
      vars(cut:clarity),
      funs(as.ordered(ifelse(is.na(.), calc_moda(.), as.character(.)))))</code></pre>
<div id="check" class="section level4">
<h4>check</h4>
<p>Con los datos imputados podemos ver cuanto se ajusta nuestro <em>invento</em> con la base original</p>
<pre class="r"><code>mis_datos$tipo &lt;- &quot;original&quot;
datos_imp$tipo &lt;- &quot;imputado&quot;

datos_imp %&gt;%
   rbind(mis_datos) %&gt;%
   select(carat, depth, price, x, tipo) %&gt;%
   gather(key, value, -tipo) %&gt;%
   ggplot(aes(x = value, fill = tipo))+
   geom_density(alpha = 0.8) +
   facet_wrap(~ key, scales = &quot;free&quot;) +
   scale_fill_brewer(type = &quot;qual&quot;, palette = 4, direction = 1) +
   theme_minimal() + labs(title=&quot;Imputación con media aritmética - variables numéricas&quot;)</code></pre>
<p><img src="/rmarkdown-libs/figure-html4/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>datos_imp %&gt;%
   rbind(mis_datos) %&gt;%
   select(color, cut, tipo) %&gt;%
   gather(key, value, -tipo) %&gt;%
   ggplot(aes(x = value, fill = tipo))+
   geom_bar(alpha = 0.8, position = position_dodge()) +
   facet_wrap(~ key, scales = &quot;free&quot;) +
   scale_fill_brewer(type = &quot;qual&quot;, palette = 4, direction = 1) +
   theme_minimal() + labs(title=&quot;Imputación con moda - variables categóricas&quot;)</code></pre>
<p><img src="/rmarkdown-libs/figure-html4/unnamed-chunk-3-2.png" width="672" /></p>
<p>Es facilmnte apreciable como tqnto en las variables numéricas como en las categóricas, la tendencia central está exagerada y se aleja de la distribución original.</p>
</div>
</div>
<div id="imputacion-multiple" class="section level3">
<h3>Imputación multiple</h3>
<p>una de las metodologias mas utilizadas para la obtencion de una uestra imputada mas <em>correcta</em> es la que utliza tecnicas de imputcoin multiple, es decir imputar mas de una base de datos. Esto permite utlizar las <em>n</em> bases imputadas para hacer <em>n</em> modelos, que posteriormente se poolean (lo siento, no se como diablos se traduce eso…) con la ventaja de que el model final da cuenta de las pequeñas diferencias de las bases imputadas.
LA mayoría de las librería permite calibrar bastante la generacion de las bases, además de la metodología para la imputacion de los valores. Uno de los paquetes mejor documentados es el <a href="http://stefvanbuuren.github.io/mice/">mice</a></p>
</div>
</div>
</div>
